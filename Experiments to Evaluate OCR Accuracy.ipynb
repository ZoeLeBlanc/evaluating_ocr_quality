{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import os\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "from gensim.models import ldamodel, doc2vec, LsiModel \n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import string\n",
    "import csv\n",
    "import math\n",
    "import statistics\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "# nltk.download('stopwords')\n",
    "from collections import OrderedDict, Counter, namedtuple\n",
    "import random\n",
    "import codecs, difflib, Levenshtein, distance\n",
    "import rpy2\n",
    "from datasketch import MinHash\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "%load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘readr’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:textreuse’:\n",
      "\n",
      "    tokenize\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "install.packages(\"textreuse\", repos='http://cran.us.r-project.org', quiet=TRUE)\n",
    "install.packages(\"readr\", repos='http://cran.us.r-project.org', quiet=TRUE)\n",
    "library(\"textreuse\")\n",
    "library(\"readr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First Test: Egyptian Gazette 1947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_unordered = pd.read_csv('./data/ocr_test_newspaper_egyptian_gazette_one_page_unordered.csv')\n",
    "eg_ordered = pd.read_csv('./data/ocr_test_newspaper_egyptian_gazette_one_page_ordered.csv')\n",
    "ocr_values = [eg_unordered['base_file_name'].iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Arab Scribe January 5 1964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eg_unordered = pd.read_csv('./data/ocr_test_magazine_arab_scribe_unordered.csv')\n",
    "eg_ordered = pd.read_csv('./data/ocr_test_magazine_arab_scribe_ordered.csv')\n",
    "\n",
    "eg_ordered['contains_image'].fillna(value=False, inplace=True)\n",
    "\n",
    "for index, row in eg_ordered.iterrows():\n",
    "    if math.isnan(row['page_number']):\n",
    "        pgn = row['base_file_name'].split('imagefile')[0][-3:]\n",
    "        pgn = pgn.split('_')[0]\n",
    "        eg_ordered.loc[index, 'page_number'] = int(pgn)\n",
    "\n",
    "groupby_df = eg_ordered.groupby('page_number')['google_vision_text'].apply(' '.join).reset_index()\n",
    "eg_ordered = eg_ordered.drop_duplicates(subset=['page_number'], keep='first')\n",
    "eg_ordered = eg_ordered.drop(columns='google_vision_text')\n",
    "final_df = pd.merge(eg_ordered, groupby_df, on='page_number', how='outer')\n",
    "eg_ordered = final_df.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words w/ or w/o punctuation and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenize(text):\n",
    "    if not text:\n",
    "#       print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "        text = ''\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "def process_text(df, punc):\n",
    "\n",
    "    final_doc = []\n",
    "    for index, row in df.iterrows():\n",
    "        page = []\n",
    "        raw_text = row['google_vision_text']\n",
    "        tokens = custom_tokenize(raw_text)\n",
    "        for t in tokens:\n",
    "            if punc:\n",
    "                if t.lower() in string.punctuation:\n",
    "                    continue\n",
    "                elif t.lower() in stopwords.words('english'):\n",
    "                    continue\n",
    "                else:\n",
    "                    final_doc.append(t.lower())\n",
    "                    page.append(t.lower())\n",
    "            else: \n",
    "                final_doc.append(t.lower())\n",
    "    text = ' '.join(final_doc)\n",
    "    return final_doc, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_list, order_text = process_text(eg_ordered, True)\n",
    "unorder_list, unorder_text = process_text(eg_unordered, True)\n",
    "all_documents = [order_text, unorder_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_order = eg_ordered.sample(frac=1).reset_index(drop=True)\n",
    "random_unorder = eg_unordered.sample(frac=1).reset_index(drop=True)\n",
    "rorder_list, rorder_text = process_text(random_order, True)\n",
    "runorder_list, runorder_text = process_text(random_unorder, True)\n",
    "random_all_documents = [rorder_text, runorder_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_full_issue(all_documents, ocr_values, full_issues_ocr):\n",
    "    # Count n grams frequencies and calculate cosine similarity between two docs. \n",
    "    counts = CountVectorizer(ngram_range=(1,5))\n",
    "    counts_matrix = counts.fit_transform(all_documents)\n",
    "    cos = cosine_similarity(counts_matrix[0:1], counts_matrix)\n",
    "    print('Count Vectorizer', cos[0][1])\n",
    "    ocr_values.append(cos[0][1])\n",
    "    \n",
    "    # Calculate tf-idf cosine similarity (nltk or spacy text the same)\n",
    "    tokenize = lambda doc: doc.lower().split(\" \")\n",
    "    tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize, ngram_range=(1,1))\n",
    "    tfidf_matrix = tfidf.fit_transform(all_documents)\n",
    "\n",
    "    cos = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "    print('TF-IDF Vectorizer', cos)\n",
    "    ocr_values.append(cos[0][1])\n",
    "    \n",
    "    # Calculate similarity using GLOVE and SPACY\n",
    "    order_doc = nlp(order_text)\n",
    "    unorder_doc = nlp(unorder_text)\n",
    "    sim_doc = order_doc.similarity(unorder_doc)\n",
    "    print('Spacy GLOVE', sim_doc)\n",
    "    #https://stats.stackexchange.com/questions/304217/how-is-the-similarity-method-in-spacy-computed\n",
    "    ocr_values.append(sim_doc)\n",
    "    \n",
    "    # Calculate jaccard ratio. Takes list of tokens\n",
    "    jac = 1 - distance.jaccard(order_list, unorder_list)\n",
    "    print('Jaccard', jac)\n",
    "    ocr_values.append(jac)\n",
    "    \n",
    "    # use gensim's similarity matrix and lsi to calculate cosine\n",
    "    all_tokens = [order_list, unorder_list]\n",
    "    dictionary = Dictionary(all_tokens)\n",
    "    corpus = [dictionary.doc2bow(text) for text in all_tokens]\n",
    "    lsi = LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "    sim = MatrixSimilarity(lsi[corpus])\n",
    "    lsi_cos = [ t[1][1] for t in list(enumerate(sim))]\n",
    "    lsi_cos = lsi_cos[0]\n",
    "    print('LSI', lsi_cos)\n",
    "    ocr_values.append(lsi_cos)\n",
    "    #https://radimrehurek.com/gensim/tut3.html\n",
    "    \n",
    "    if os.path.isfile(full_issues_ocr):\n",
    "        final_metrics = pd.read_csv(full_issues_ocr)\n",
    "        ocr_values.append(datetime.date.today())\n",
    "        final_metrics.loc[len(final_metrics.index)] = ocr_values\n",
    "        final_metrics.to_csv(full_issues_ocr, index=False)\n",
    "    else:\n",
    "        cols = ['base_file_name', 'num_pages', 'countsvec_cos', 'tfidfvec_cos', 'spacy_sim', 'jaccard_sim', 'lsi_cos', 'date_run']\n",
    "        ocr_values.append(datetime.date.today())\n",
    "        final_df = pd.DataFrame([ocr_values], columns=cols)\n",
    "        final_df.to_csv(full_issues_ocr, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer 0.959538261301\n",
      "TF-IDF Vectorizer [[ 1.          0.93357973]]\n",
      "Spacy GLOVE 0.999952728742\n",
      "Jaccard 0.8636978579481398\n",
      "LSI 0.997655\n"
     ]
    }
   ],
   "source": [
    "ocr_values = [eg_unordered['base_file_name'].iloc[0], len(eg_unordered.index)]\n",
    "process_full_issue(all_documents, ocr_values, 'ocr_accuracy_full_issue_arab_scribe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_pages(order, unorder):\n",
    "    %%R -i order\n",
    "    %%R -i unorder\n",
    "#     order <- read_file(\"order_doc.txt\")\n",
    "#     unorder <- read_file(\"unorder_doc.txt\")\n",
    "    %%R perfect = align_local(order, order)\n",
    "    %%R actual = align_local(order, unorder)\n",
    "    %%R smw <- actual$score / perfect$score\n",
    "    %%R smw\n",
    "    %%R -o smw\n",
    "    print(smw)\n",
    "    return smw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(all_documents, order_text, unorder_text, order_list, unorder_list, ocr_values, page_ocr):\n",
    "    # Count n grams frequencies and calculate cosine similarity between two docs. \n",
    "    counts = CountVectorizer(ngram_range=(1,5))\n",
    "    counts_matrix = counts.fit_transform(all_documents)\n",
    "    cos = cosine_similarity(counts_matrix[0:1], counts_matrix)\n",
    "    print('Count Vectorizer', cos[0][1])\n",
    "    ocr_values.append(cos[0][1])\n",
    "    \n",
    "    # Calculate tf-idf cosine similarity (nltk or spacy text the same)\n",
    "    tokenize = lambda doc: doc.lower().split(\" \")\n",
    "    tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize, ngram_range=(1,1))\n",
    "    tfidf_matrix = tfidf.fit_transform(all_documents)\n",
    "\n",
    "    cos = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "    print('TF-IDF Vectorizer', cos)\n",
    "    ocr_values.append(cos[0][1])\n",
    "    \n",
    "#     # Calculate similarity using GLOVE and SPACY\n",
    "#     order_doc = nlp(order_text)\n",
    "#     unorder_doc = nlp(unorder_text)\n",
    "#     sim_doc = order_doc.similarity(unorder_doc)\n",
    "#     print('Spacy GLOVE', sim_doc)\n",
    "#     #https://stats.stackexchange.com/questions/304217/how-is-the-similarity-method-in-spacy-computed\n",
    "#     ocr_values.append(sim_doc)\n",
    "    \n",
    "    # Calculate jaccard ratio. Takes list of tokens\n",
    "    jac = 1 - distance.jaccard(order_list, unorder_list)\n",
    "    print('Jaccard', jac)\n",
    "    ocr_values.append(jac)\n",
    "    \n",
    "    # use gensim's similarity matrix and lsi to calculate cosine\n",
    "    all_tokens = [order_list, unorder_list]\n",
    "    dictionary = Dictionary(all_tokens)\n",
    "    corpus = [dictionary.doc2bow(text) for text in all_tokens]\n",
    "    lsi = LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "    sim = MatrixSimilarity(lsi[corpus])\n",
    "    lsi_cos = [ t[1][1] for t in list(enumerate(sim))]\n",
    "    lsi_cos = lsi_cos[0]\n",
    "    print('LSI', lsi_cos)\n",
    "    ocr_values.append(lsi_cos)\n",
    "    #https://radimrehurek.com/gensim/tut3.html\n",
    "    \n",
    "#     align = align_pages(order_text, unorder_text)\n",
    "#     print('smw', align)\n",
    "#     ocr_values.append(align)\n",
    "    \n",
    "#     if os.path.isfile(page_ocr):\n",
    "#         final_metrics = pd.read_csv(page_ocr)\n",
    "#         ocr_values.append(len(order_text))\n",
    "#         ocr_values.append(len(unorder_text))\n",
    "#         ocr_values.append(datetime.date.today())\n",
    "#         final_metrics.loc[len(final_metrics.index)] = ocr_values\n",
    "#         print(final_metrics)\n",
    "#         final_metrics.to_csv(page_ocr, index=False)\n",
    "#     else:\n",
    "#         ocr_values.append(len(order_text))\n",
    "#         ocr_values.append(len(unorder_text))\n",
    "#         ocr_values.append(datetime.date.today())\n",
    "#         cols = ['base_file_name', 'page_number', 'countsvec_cos', 'tfidfvec_cos', 'spacy_sim', 'jaccard_sim', 'lsi_cos','smw_align', 'len_order', 'len_unorder', 'date_run']\n",
    "#         final_df = pd.DataFrame([ocr_values], columns=cols)\n",
    "#         final_df.to_csv(page_ocr, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.82814880195\n",
      "TF-IDF Vectorizer [[ 1.          0.89692841]]\n",
      "Jaccard 0.8888888888888888\n",
      "LSI 0.960863\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.577078469596\n",
      "TF-IDF Vectorizer [[ 1.          0.90497357]]\n",
      "Jaccard 0.902127659574468\n",
      "LSI 0.97168\n",
      "Count Vectorizer 0.667523014697\n",
      "TF-IDF Vectorizer [[ 1.          0.98945976]]\n",
      "Jaccard 0.9911504424778761\n",
      "LSI 0.995149\n",
      "Count Vectorizer 0.880603989861\n",
      "TF-IDF Vectorizer [[ 1.         0.8319078]]\n",
      "Jaccard 0.8493975903614458\n",
      "LSI 0.938007\n",
      "Count Vectorizer 0.502186625725\n",
      "TF-IDF Vectorizer [[ 1.          0.95695887]]\n",
      "Jaccard 0.9532967032967034\n",
      "LSI 0.985997\n",
      "Count Vectorizer 0.719260322127\n",
      "TF-IDF Vectorizer [[ 1.          0.76826979]]\n",
      "Jaccard 0.7668393782383419\n",
      "LSI 0.930278\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.474552860472\n",
      "TF-IDF Vectorizer [[ 1.          0.83136576]]\n",
      "Jaccard 0.8299319727891157\n",
      "LSI 0.931771\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.851724372712\n",
      "TF-IDF Vectorizer [[ 1.          0.91240776]]\n",
      "Jaccard 0.9180327868852459\n",
      "LSI 0.973958\n",
      "Count Vectorizer 0.816490186146\n",
      "TF-IDF Vectorizer [[ 1.          0.85566261]]\n",
      "Jaccard 0.8458646616541353\n",
      "LSI 0.956706\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.946835443038\n",
      "TF-IDF Vectorizer [[ 1.         0.9858546]]\n",
      "Jaccard 0.9866071428571429\n",
      "LSI 0.997003\n",
      "Count Vectorizer 0.973760932945\n",
      "TF-IDF Vectorizer [[ 1.          0.99135887]]\n",
      "Jaccard 0.9916317991631799\n",
      "LSI 0.997947\n",
      "Count Vectorizer 0.806949090087\n",
      "TF-IDF Vectorizer [[ 1.          0.81413656]]\n",
      "Jaccard 0.7958115183246073\n",
      "LSI 0.956607\n",
      "Count Vectorizer 0.913347192754\n",
      "TF-IDF Vectorizer [[ 1.          0.92842249]]\n",
      "Jaccard 0.926530612244898\n",
      "LSI 0.980468\n",
      "Count Vectorizer 0.990655068179\n",
      "TF-IDF Vectorizer [[ 1.          0.99130361]]\n",
      "Jaccard 0.991701244813278\n",
      "LSI 0.997076\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.87419598227\n",
      "TF-IDF Vectorizer [[ 1.          0.90208785]]\n",
      "Jaccard 0.8991825613079019\n",
      "LSI 0.974336\n",
      "Count Vectorizer 0.633563166159\n",
      "TF-IDF Vectorizer [[ 1.          0.89559839]]\n",
      "Jaccard 0.8708609271523179\n",
      "LSI 0.984509\n",
      "Count Vectorizer 0.634213612304\n",
      "TF-IDF Vectorizer [[ 1.         0.8548374]]\n",
      "Jaccard 0.8038147138964578\n",
      "LSI 0.977318\n",
      "Count Vectorizer 0.72807190848\n",
      "TF-IDF Vectorizer [[ 1.          0.82936111]]\n",
      "Jaccard 0.8043478260869565\n",
      "LSI 0.980841\n",
      "Count Vectorizer 0.659085356421\n",
      "TF-IDF Vectorizer [[ 1.          0.89578129]]\n",
      "Jaccard 0.875\n",
      "LSI 0.982964\n",
      "Count Vectorizer 0.618982550732\n",
      "TF-IDF Vectorizer [[ 1.          0.91959905]]\n",
      "Jaccard 0.9142091152815014\n",
      "LSI 0.984869\n",
      "Count Vectorizer 0.562029676817\n",
      "TF-IDF Vectorizer [[ 1.          0.90059139]]\n",
      "Jaccard 0.8841607565011821\n",
      "LSI 0.974194\n",
      "Count Vectorizer 0.575053092114\n",
      "TF-IDF Vectorizer [[ 1.          0.86934994]]\n",
      "Jaccard 0.8487584650112867\n",
      "LSI 0.969162\n",
      "Count Vectorizer 0.528474751149\n",
      "TF-IDF Vectorizer [[ 1.          0.86797561]]\n",
      "Jaccard 0.8542274052478134\n",
      "LSI 0.966846\n",
      "Count Vectorizer 0.98749747979\n",
      "TF-IDF Vectorizer [[ 1.          0.98731255]]\n",
      "Jaccard 0.9873949579831933\n",
      "LSI 0.994804\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.988042161277\n",
      "TF-IDF Vectorizer [[ 1.          0.97543485]]\n",
      "Jaccard 0.9720670391061452\n",
      "LSI 0.995496\n",
      "Count Vectorizer 0.904033847402\n",
      "TF-IDF Vectorizer [[ 1.          0.94973967]]\n",
      "Jaccard 0.9539473684210527\n",
      "LSI 0.979815\n",
      "Count Vectorizer 0.92819716255\n",
      "TF-IDF Vectorizer [[ 1.          0.92033966]]\n",
      "Jaccard 0.9136212624584718\n",
      "LSI 0.973096\n",
      "Count Vectorizer 0.896393171959\n",
      "TF-IDF Vectorizer [[ 1.          0.90671085]]\n",
      "Jaccard 0.8984126984126984\n",
      "LSI 0.984964\n",
      "Count Vectorizer 0.928668766588\n",
      "TF-IDF Vectorizer [[ 1.          0.93761594]]\n",
      "Jaccard 0.9367816091954023\n",
      "LSI 0.983998\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.966603252323\n",
      "TF-IDF Vectorizer [[ 1.          0.99165675]]\n",
      "Jaccard 0.9908814589665653\n",
      "LSI 0.997784\n",
      "Count Vectorizer 0.932386548592\n",
      "TF-IDF Vectorizer [[ 1.          0.94337992]]\n",
      "Jaccard 0.9314641744548287\n",
      "LSI 0.992686\n",
      "Count Vectorizer 0.963369685851\n",
      "TF-IDF Vectorizer [[ 1.          0.98207779]]\n",
      "Jaccard 0.976897689768977\n",
      "LSI 0.969442\n",
      "Count Vectorizer 0.990709092358\n",
      "TF-IDF Vectorizer [[ 1.         0.9669979]]\n",
      "Jaccard 0.9689119170984456\n",
      "LSI 0.991279\n",
      "Count Vectorizer 0.69114254955\n",
      "TF-IDF Vectorizer [[ 1.          0.92590264]]\n",
      "Jaccard 0.9074889867841409\n",
      "LSI 0.980993\n",
      "Count Vectorizer 0.662669934651\n",
      "TF-IDF Vectorizer [[ 1.          0.89402393]]\n",
      "Jaccard 0.8832684824902723\n",
      "LSI 0.967407\n",
      "Count Vectorizer 0.963809715503\n",
      "TF-IDF Vectorizer [[ 1.          0.94937558]]\n",
      "Jaccard 0.9465020576131687\n",
      "LSI 0.981867\n",
      "Count Vectorizer 0.980273831534\n",
      "TF-IDF Vectorizer [[ 1.          0.96113456]]\n",
      "Jaccard 0.9509594882729211\n",
      "LSI 0.992636\n",
      "Count Vectorizer 0.810202347697\n",
      "TF-IDF Vectorizer [[ 1.          0.86816169]]\n",
      "Jaccard 0.8461538461538461\n",
      "LSI 0.955569\n",
      "Count Vectorizer 0.961273176471\n",
      "TF-IDF Vectorizer [[ 1.          0.93044323]]\n",
      "Jaccard 0.9299610894941635\n",
      "LSI 0.98071\n",
      "Count Vectorizer 0.858100334506\n",
      "TF-IDF Vectorizer [[ 1.          0.84667722]]\n",
      "Jaccard 0.8217213114754098\n",
      "LSI 0.954705\n",
      "Count Vectorizer 0.6785670429\n",
      "TF-IDF Vectorizer [[ 1.          0.93496033]]\n",
      "Jaccard 0.9319148936170213\n",
      "LSI 0.975634\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.693551369325\n",
      "TF-IDF Vectorizer [[ 1.          0.75613535]]\n",
      "Jaccard 0.7571428571428571\n",
      "LSI 0.915119\n",
      "Count Vectorizer 0.476796495833\n",
      "TF-IDF Vectorizer [[ 1.          0.95962499]]\n",
      "Jaccard 0.9585365853658536\n",
      "LSI 0.989691\n",
      "Count Vectorizer 0.459274133044\n",
      "TF-IDF Vectorizer [[ 1.         0.8034958]]\n",
      "Jaccard 0.808695652173913\n",
      "LSI 0.935061\n",
      "Count Vectorizer 0.983587338804\n",
      "TF-IDF Vectorizer [[ 1.          0.93242533]]\n",
      "Jaccard 0.9389312977099237\n",
      "LSI 0.979217\n",
      "Count Vectorizer 0.658715241053\n",
      "TF-IDF Vectorizer [[ 1.          0.82650407]]\n",
      "Jaccard 0.83125\n",
      "LSI 0.952055\n",
      "Count Vectorizer 0.591725660526\n",
      "TF-IDF Vectorizer [[ 1.          0.96466136]]\n",
      "Jaccard 0.9661654135338346\n",
      "LSI 0.9869\n",
      "Count Vectorizer 0.849881859798\n",
      "TF-IDF Vectorizer [[ 1.          0.86938029]]\n",
      "Jaccard 0.8571428571428571\n",
      "LSI 0.960167\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.718485423314\n",
      "TF-IDF Vectorizer [[ 1.          0.78574854]]\n",
      "Jaccard 0.822463768115942\n",
      "LSI 0.90737\n",
      "Count Vectorizer 0.908048376403\n",
      "TF-IDF Vectorizer [[ 1.         0.9576097]]\n",
      "Jaccard 0.9655172413793104\n",
      "LSI 0.971544\n",
      "Count Vectorizer 0.725624047826\n",
      "TF-IDF Vectorizer [[ 1.         0.7841877]]\n",
      "Jaccard 0.7594339622641509\n",
      "LSI 0.940026\n",
      "Count Vectorizer 0.937202338053\n",
      "TF-IDF Vectorizer [[ 1.          0.95918673]]\n",
      "Jaccard 0.9681818181818181\n",
      "LSI 0.98756\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.35646407744\n",
      "TF-IDF Vectorizer [[ 1.          0.64248671]]\n",
      "Jaccard 0.6577946768060836\n",
      "LSI 0.827565\n",
      "Count Vectorizer 0.451916258538\n",
      "TF-IDF Vectorizer [[ 1.         0.9582515]]\n",
      "Jaccard 0.9597156398104265\n",
      "LSI 0.988241\n",
      "Count Vectorizer 0.411389303938\n",
      "TF-IDF Vectorizer [[ 1.          0.80907121]]\n",
      "Jaccard 0.823045267489712\n",
      "LSI 0.923703\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.446117634146\n",
      "TF-IDF Vectorizer [[ 1.          0.77091201]]\n",
      "Jaccard 0.8025210084033614\n",
      "LSI 0.920801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer 0.877887273731\n",
      "TF-IDF Vectorizer [[ 1.          0.90131917]]\n",
      "Jaccard 0.92\n",
      "LSI 0.964979\n",
      "Count Vectorizer 0.565495039179\n",
      "TF-IDF Vectorizer [[ 1.          0.81886335]]\n",
      "Jaccard 0.8441558441558441\n",
      "LSI 0.935804\n",
      "Count Vectorizer 0.946328221974\n",
      "TF-IDF Vectorizer [[ 1.          0.93843714]]\n",
      "Jaccard 0.9318181818181818\n",
      "LSI 0.987714\n",
      "Count Vectorizer 0.607973599046\n",
      "TF-IDF Vectorizer [[ 1.          0.78125839]]\n",
      "Jaccard 0.7939110070257611\n",
      "LSI 0.923838\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 1.0\n",
      "TF-IDF Vectorizer [[ 1.  1.]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(eg_unordered.index)):\n",
    "    ocr_values = [eg_unordered['base_file_name'].iloc[i], i]\n",
    "    order_list, order_text = process_text(eg_ordered.iloc[[i]], True)\n",
    "    unorder_list, unorder_text = process_text(eg_unordered.iloc[[i]], True)\n",
    "    all_documents = [order_text, unorder_text]\n",
    "    process_page(all_documents, order_text, unorder_text, order_list, unorder_list, ocr_values, 'ocr_accuracy_page_level_arab_scribe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n",
      "Count Vectorizer 0.94301968224\n",
      "TF-IDF Vectorizer [[ 1.         0.9322488]]\n",
      "Jaccard 1.0\n",
      "LSI 1.0\n"
     ]
    }
   ],
   "source": [
    "random_order = eg_ordered.sample(frac=1).reset_index(drop=True)\n",
    "random_unorder = eg_unordered.sample(frac=1).reset_index(drop=True)\n",
    "rorder_list, rorder_text = process_text(random_order, True)\n",
    "runorder_list, runorder_text = process_text(random_unorder, True)\n",
    "random_all_documents = [rorder_text, runorder_text]\n",
    "for i in range(0, len(random_order.index)):\n",
    "    ocr_values = [random_order['base_file_name'].iloc[i], i]\n",
    "    rorder_list, rorder_text = process_text(random_order.iloc[[i]], True)\n",
    "    order_list, order_text = process_text(eg_ordered.iloc[[i]], True)\n",
    "#     runorder_list, runorder_text = process_text(random_unorder.iloc[[i]], True)\n",
    "    random_all_documents = [rorder_text, order_text]\n",
    "    process_page(all_documents, rorder_text, order_text, rorder_list, rorder_list, ocr_values, 'ocr_accuracy_page_level_arab_scribe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count n grams frequencies and calculate cosine similarity between two docs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959538261301\n"
     ]
    }
   ],
   "source": [
    "counts = CountVectorizer(ngram_range=(1,5))\n",
    "counts_matrix = counts.fit_transform(all_documents)\n",
    "cos = cosine_similarity(counts_matrix[0:1], counts_matrix)\n",
    "print(cos[0][1])\n",
    "ocr_values.append(cos[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tf-idf cosine similarity (nltk or spacy text the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.93357973]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenize = lambda doc: doc.lower().split(\" \")\n",
    "tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize, ngram_range=(1,1))\n",
    "tfidf_matrix = tfidf.fit_transform(all_documents)\n",
    "\n",
    "cos = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "print(cos)\n",
    "ocr_values.append(cos[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity using GLOVE and SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999952728742\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "order_doc = nlp(order_text)\n",
    "unorder_doc = nlp(unorder_text)\n",
    "sim_doc = order_doc.similarity(unorder_doc)\n",
    "print(sim_doc)\n",
    "#https://stats.stackexchange.com/questions/304217/how-is-the-similarity-method-in-spacy-computed\n",
    "ocr_values.append(sim_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205680"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write spacy texts for R\n",
    "f = open('order_doc.txt', 'wt', encoding='utf-8')\n",
    "f.write(order_text)\n",
    "f = open('unorder_doc.txt', 'wt', encoding='utf-8')\n",
    "f.write(unorder_text)\n",
    "#Create tokens from spacy tokens\n",
    "# order_doc_tokens = []\n",
    "# for t in order_doc:\n",
    "#     order_doc_tokens.append(t.text)\n",
    "# unorder_doc_tokens = []\n",
    "# for t in jane_doc:\n",
    "#     unorder_doc_tokens.append(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with completely random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(unorder_text))\n",
    "# with open('jane_austen.txt', 'r') as myfile:\n",
    "#   jane = myfile.read()\n",
    "# jane = jane[:17457]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate jaccard ratio. Takes list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersection : new set with elements common to s and t\n",
    "# union : new set with elements from both s and t\n",
    "# difference: new set with elements in s but not in t\n",
    "# symmetric difference: new set with elements in either s or t but not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8636978579481398\n"
     ]
    }
   ],
   "source": [
    "jac = 1 - distance.jaccard(order_list, unorder_list)\n",
    "print(jac)\n",
    "# m1, m2 = MinHash(num_perm=256), MinHash(num_perm=256)\n",
    "# for d in order_list:\n",
    "#     m1.update(d.encode('utf8'))\n",
    "# for d in unorder_list:\n",
    "#     m2.update(d.encode('utf8'))\n",
    "# print(\"Estimated Jaccard for data1 and data2 is\", m1.jaccard(m2))\n",
    "ocr_values.append(jac)\n",
    "# ocr_values.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gensim's similarity matrix and lsi to calculate cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997655\n"
     ]
    }
   ],
   "source": [
    "all_tokens = [order_list, unorder_list]\n",
    "dictionary = Dictionary(all_tokens)\n",
    "corpus = [dictionary.doc2bow(text) for text in all_tokens]\n",
    "lsi = LsiModel(corpus, id2word=dictionary, num_topics=2)\n",
    "sim = MatrixSimilarity(lsi[corpus])\n",
    "lsi_cos = [ t[1][1] for t in list(enumerate(sim))]\n",
    "lsi_cos = lsi_cos[0]\n",
    "print(lsi_cos)\n",
    "ocr_values.append(lsi_cos)\n",
    "#https://radimrehurek.com/gensim/tut3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use textreuse align local for Smith Waterman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "install.packages(\"textreuse\", repos='http://cran.us.r-project.org', quiet=TRUE)\n",
    "install.packages(\"readr\", repos='http://cran.us.r-project.org', quiet=TRUE)\n",
    "library(\"textreuse\")\n",
    "library(\"readr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -o smw\n",
    "order <- read_file(\"order_doc.txt\")\n",
    "unorder <- read_file(\"unorder_doc.txt\")\n",
    "perfect = align_local(order, order)\n",
    "actual = align_local(order, unorder)\n",
    "actual\n",
    "smw <- actual$score / perfect$score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_values.append(smw[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_file_name</th>\n",
       "      <th>countsvec_cos</th>\n",
       "      <th>tfidfvec_cos</th>\n",
       "      <th>spacy_sim</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>smw_align</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_lucida_app/media/Egyptian_Gazette_1947_J...</td>\n",
       "      <td>0.524825</td>\n",
       "      <td>0.58027</td>\n",
       "      <td>0.999314</td>\n",
       "      <td>0.522356</td>\n",
       "      <td>0.019961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      base_file_name  countsvec_cos  \\\n",
       "0  image_lucida_app/media/Egyptian_Gazette_1947_J...       0.524825   \n",
       "\n",
       "   tfidfvec_cos  spacy_sim  jaccard_sim  smw_align  \n",
       "0       0.58027   0.999314     0.522356   0.019961  "
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['base_file_name', 'countsvec_cos', 'tfidfvec_cos', 'spacy_sim', 'jaccard_sim', 'lsi_cos', 'smw_align']\n",
    "final_df = pd.DataFrame([ocr_values], columns=cols)\n",
    "final_df\n",
    "# final_df.to_csv('ocr_quality_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An important class of problems that Jaccard similarity addresses well is that of finding textually similar documents in a large corpus such as the Web or a collection of news articles. We should understand that the aspect of similarity we are looking at here is character-level similarity, not “similar meaning,” which requires us to examine the words in the documents and their uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
